{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "interpret_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMD+VtLTaE5U0L16MSRa/bW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37420c84459e426d9c9777389fa52f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_6af640fbd5b34992a58d9b2f0c99df47",
            "_dom_classes": [],
            "description": "Tweet:",
            "_model_name": "TextModel",
            "placeholder": "Enter tweet to test here",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "You & your children won’t be SAFE in Biden’s America, and neither will anyone else!",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ee0b744719a4c1d9ff29dc6334c9f99"
          }
        },
        "6af640fbd5b34992a58d9b2f0c99df47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ee0b744719a4c1d9ff29dc6334c9f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "75%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": "80px",
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssdorsey/transformers-interp/blob/main/interpret_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19nZ4vypeoV"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip2lvC-NjaSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3172efa-3623-4388-adc8-c9e7360d58e1"
      },
      "source": [
        "# Install the packages we need\n",
        "try:\n",
        "    import transformers\n",
        "except:\n",
        "    !pip install transformers -q\n",
        "\n",
        "try:\n",
        "    import captum\n",
        "except:\n",
        "    !pip install captum -q\n",
        "\n",
        "# !pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 16.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 61.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 61.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 4.4MB 18.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_mHAr1JVdwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257e568a-2396-4c86-b3e3-69f17ba23d9d"
      },
      "source": [
        "# download the model\n",
        "import os\n",
        "# if 'model' not in os.listdir():\n",
        "!wget -O model.zip https://www.dropbox.com/sh/sx6g8hp8miylrvk/AADr49JboXw26njcHn5Xloqla?dl=1 # this is the \"polarizing\" model\n",
        "!unzip model.zip -d model\n",
        "\n",
        "# download the script to display the interpretation \n",
        "# !wget -O robertainterp.py https://www.dropbox.com/sh/j6v5kgbmgki15ap/AABI4b4sx5gnJCvPkD8oE5lia?dl=1 -q\n",
        "\n",
        "# code to display\n",
        "from ipywidgets import interact, widgets, Layout\n",
        "from IPython.display import display, clear_output\n",
        "# code to interpret\n",
        "# from robertainterp import robertainterp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-23 04:33:11--  https://www.dropbox.com/sh/sx6g8hp8miylrvk/AADr49JboXw26njcHn5Xloqla?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/dl/sx6g8hp8miylrvk/AADr49JboXw26njcHn5Xloqla [following]\n",
            "--2021-02-23 04:33:12--  https://www.dropbox.com/sh/dl/sx6g8hp8miylrvk/AADr49JboXw26njcHn5Xloqla\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com/zip_download_get/As3m1qJYnYm7S7TV714F8yEI4MlJtT_JxmZol7WDnW2qn0vXu3ycQScirFHMdjXBCV7nCyOAjNvffipCahTXWDcktf-pl2IQOf2Dq5tXlYRmuw?dl=1 [following]\n",
            "--2021-02-23 04:33:12--  https://uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com/zip_download_get/As3m1qJYnYm7S7TV714F8yEI4MlJtT_JxmZol7WDnW2qn0vXu3ycQScirFHMdjXBCV7nCyOAjNvffipCahTXWDcktf-pl2IQOf2Dq5tXlYRmuw?dl=1\n",
            "Resolving uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com (uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com (uc34fade432d9889a6832edb6b60.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 505810019 (482M) [application/zip]\n",
            "Saving to: ‘model.zip’\n",
            "\n",
            "model.zip           100%[===================>] 482.38M   102MB/s    in 4.7s    \n",
            "\n",
            "2021-02-23 04:33:17 (102 MB/s) - ‘model.zip’ saved [505810019/505810019]\n",
            "\n",
            "Archive:  model.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: model/vocab.json        \n",
            " extracting: model/merges.txt        \n",
            " extracting: model/config.json       \n",
            " extracting: model/model_args.json   \n",
            " extracting: model/eval_results.txt  \n",
            " extracting: model/training_args.bin  \n",
            " extracting: model/pytorch_model.bin  \n",
            " extracting: model/tokenizer_config.json  \n",
            " extracting: model/special_tokens_map.json  \n",
            " extracting: model/cached_dev_roberta_128_2_796  \n",
            " extracting: model/cached_train_roberta_128_2_3172  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv1NUl1yJW4w",
        "outputId": "eb1fb499-4e49-45b1-e22b-39d854409cbf"
      },
      "source": [
        "!ls model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cached_dev_roberta_128_2_796\t merges.txt\t\t  tokenizer_config.json\n",
            "cached_train_roberta_128_2_3172  model_args.json\t  training_args.bin\n",
            "config.json\t\t\t pytorch_model.bin\t  vocab.json\n",
            "eval_results.txt\t\t special_tokens_map.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMrucZkqjGK1"
      },
      "source": [
        "from typing import Any, Iterable, List, Tuple, Union\n",
        "# from captum.attr import visualization as viz\n",
        "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
        "\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "from enum import Enum\n",
        "from typing import Any, Iterable, List, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.figure import Figure\n",
        "from matplotlib.pyplot import axis, figure\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from numpy import ndarray\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaModel, AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "try:\n",
        "    from IPython.core.display import display, HTML\n",
        "    HAS_IPYTHON = True\n",
        "except ImportError:\n",
        "    HAS_IPYTHON = False\n",
        "\n",
        "\n",
        "# choose device\n",
        "# load tokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
        "# slow_tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "slow_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load model\n",
        "model = RobertaModel.from_pretrained('model/')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
        "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
        "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n",
        "\n",
        "\n",
        "# label dictionary\n",
        "# label_dict = {\n",
        "#     0: 'Civil',\n",
        "#     1: 'Uncivil'\n",
        "# }\n",
        "label_dict = {\n",
        "    77: 'Not Polarizing',\n",
        "    5196: 'Polarizing',\n",
        "    11205: 'Polarizing'\n",
        "}\n",
        "\n",
        "\n",
        "try:\n",
        "    from IPython.core.display import display, HTML\n",
        "\n",
        "    HAS_IPYTHON = True\n",
        "except ImportError:\n",
        "    HAS_IPYTHON = False\n",
        "\n",
        "class ImageVisualizationMethod(Enum):\n",
        "    heat_map = 1\n",
        "    blended_heat_map = 2\n",
        "    original_image = 3\n",
        "    masked_image = 4\n",
        "    alpha_scaling = 5\n",
        "\n",
        "\n",
        "class VisualizeSign(Enum):\n",
        "    positive = 1\n",
        "    absolute_value = 2\n",
        "    negative = 3\n",
        "    all = 4\n",
        "\n",
        "\n",
        "def _prepare_image(attr_visual: ndarray):\n",
        "    return np.clip(attr_visual.astype(int), 0, 255)\n",
        "\n",
        "\n",
        "def _normalize_scale(attr: ndarray, scale_factor: float):\n",
        "    if abs(scale_factor) < 1e-5:\n",
        "        warnings.warn(\n",
        "            \"Attempting to normalize by value approximately 0, skipping normalization.\"\n",
        "            \"This likely means that attribution values are all close to 0.\"\n",
        "        )\n",
        "        return np.clip(attr, -1, 1)\n",
        "    attr_norm = attr / scale_factor\n",
        "    return np.clip(attr_norm, -1, 1)\n",
        "\n",
        "\n",
        "def _cumulative_sum_threshold(values: ndarray, percentile: Union[int, float]):\n",
        "    # given values should be non-negative\n",
        "    assert percentile >= 0 and percentile <= 100, (\n",
        "        \"Percentile for thresholding must be \" \"between 0 and 100 inclusive.\"\n",
        "    )\n",
        "    sorted_vals = np.sort(values.flatten())\n",
        "    cum_sums = np.cumsum(sorted_vals)\n",
        "    threshold_id = np.where(cum_sums >= cum_sums[-1] * 0.01 * percentile)[0][0]\n",
        "    return sorted_vals[threshold_id]\n",
        "\n",
        "\n",
        "def _normalize_image_attr(\n",
        "    attr: ndarray, sign: str, outlier_perc: Union[int, float] = 2\n",
        "):\n",
        "    attr_combined = np.sum(attr, axis=2)\n",
        "    # Choose appropriate signed values and rescale, removing given outlier percentage.\n",
        "    if VisualizeSign[sign] == VisualizeSign.all:\n",
        "        threshold = _cumulative_sum_threshold(np.abs(attr_combined), 100 - outlier_perc)\n",
        "    elif VisualizeSign[sign] == VisualizeSign.positive:\n",
        "        attr_combined = (attr_combined > 0) * attr_combined\n",
        "        threshold = _cumulative_sum_threshold(attr_combined, 100 - outlier_perc)\n",
        "    elif VisualizeSign[sign] == VisualizeSign.negative:\n",
        "        attr_combined = (attr_combined < 0) * attr_combined\n",
        "        threshold = -1 * _cumulative_sum_threshold(\n",
        "            np.abs(attr_combined), 100 - outlier_perc\n",
        "        )\n",
        "    elif VisualizeSign[sign] == VisualizeSign.absolute_value:\n",
        "        attr_combined = np.abs(attr_combined)\n",
        "        threshold = _cumulative_sum_threshold(attr_combined, 100 - outlier_perc)\n",
        "    else:\n",
        "        raise AssertionError(\"Visualize Sign type is not valid.\")\n",
        "    return _normalize_scale(attr_combined, threshold)\n",
        "\n",
        "\n",
        "def visualize_image_attr(\n",
        "    attr: ndarray,\n",
        "    original_image: Union[None, ndarray] = None,\n",
        "    method: str = \"heat_map\",\n",
        "    sign: str = \"absolute_value\",\n",
        "    plt_fig_axis: Union[None, Tuple[figure, axis]] = None,\n",
        "    outlier_perc: Union[int, float] = 2,\n",
        "    cmap: Union[None, str] = None,\n",
        "    alpha_overlay: float = 0.5,\n",
        "    show_colorbar: bool = False,\n",
        "    title: Union[None, str] = None,\n",
        "    fig_size: Tuple[int, int] = (6, 6),\n",
        "    use_pyplot: bool = True,\n",
        "):\n",
        "    r\"\"\"\n",
        "        Visualizes attribution for a given image by normalizing attribution values\n",
        "        of the desired sign (positive, negative, absolute value, or all) and displaying\n",
        "        them using the desired mode in a matplotlib figure.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            attr (numpy.array): Numpy array corresponding to attributions to be\n",
        "                        visualized. Shape must be in the form (H, W, C), with\n",
        "                        channels as last dimension. Shape must also match that of\n",
        "                        the original image if provided.\n",
        "            original_image (numpy.array, optional):  Numpy array corresponding to\n",
        "                        original image. Shape must be in the form (H, W, C), with\n",
        "                        channels as the last dimension. Image can be provided either\n",
        "                        with float values in range 0-1 or int values between 0-255.\n",
        "                        This is a necessary argument for any visualization method\n",
        "                        which utilizes the original image.\n",
        "                        Default: None\n",
        "            method (string, optional): Chosen method for visualizing attribution.\n",
        "                        Supported options are:\n",
        "\n",
        "                        1. `heat_map` - Display heat map of chosen attributions\n",
        "\n",
        "                        2. `blended_heat_map` - Overlay heat map over greyscale\n",
        "                           version of original image. Parameter alpha_overlay\n",
        "                           corresponds to alpha of heat map.\n",
        "\n",
        "                        3. `original_image` - Only display original image.\n",
        "\n",
        "                        4. `masked_image` - Mask image (pixel-wise multiply)\n",
        "                           by normalized attribution values.\n",
        "\n",
        "                        5. `alpha_scaling` - Sets alpha channel of each pixel\n",
        "                           to be equal to normalized attribution value.\n",
        "                        Default: `heat_map`\n",
        "            sign (string, optional): Chosen sign of attributions to visualize. Supported\n",
        "                        options are:\n",
        "\n",
        "                        1. `positive` - Displays only positive pixel attributions.\n",
        "\n",
        "                        2. `absolute_value` - Displays absolute value of\n",
        "                           attributions.\n",
        "\n",
        "                        3. `negative` - Displays only negative pixel attributions.\n",
        "\n",
        "                        4. `all` - Displays both positive and negative attribution\n",
        "                           values. This is not supported for `masked_image` or\n",
        "                           `alpha_scaling` modes, since signed information cannot\n",
        "                           be represented in these modes.\n",
        "                        Default: `absolute_value`\n",
        "            plt_fig_axis (tuple, optional): Tuple of matplotlib.pyplot.figure and axis\n",
        "                        on which to visualize. If None is provided, then a new figure\n",
        "                        and axis are created.\n",
        "                        Default: None\n",
        "            outlier_perc (float or int, optional): Top attribution values which\n",
        "                        correspond to a total of outlier_perc percentage of the\n",
        "                        total attribution are set to 1 and scaling is performed\n",
        "                        using the minimum of these values. For sign=`all`, outliers a\n",
        "                        nd scale value are computed using absolute value of\n",
        "                        attributions.\n",
        "                        Default: 2\n",
        "            cmap (string, optional): String corresponding to desired colormap for\n",
        "                        heatmap visualization. This defaults to \"Reds\" for negative\n",
        "                        sign, \"Blues\" for absolute value, \"Greens\" for positive sign,\n",
        "                        and a spectrum from red to green for all. Note that this\n",
        "                        argument is only used for visualizations displaying heatmaps.\n",
        "                        Default: None\n",
        "            alpha_overlay (float, optional): Alpha to set for heatmap when using\n",
        "                        `blended_heat_map` visualization mode, which overlays the\n",
        "                        heat map over the greyscaled original image.\n",
        "                        Default: 0.5\n",
        "            show_colorbar (boolean, optional): Displays colorbar for heatmap below\n",
        "                        the visualization. If given method does not use a heatmap,\n",
        "                        then a colormap axis is created and hidden. This is\n",
        "                        necessary for appropriate alignment when visualizing\n",
        "                        multiple plots, some with colorbars and some without.\n",
        "                        Default: False\n",
        "            title (string, optional): Title string for plot. If None, no title is\n",
        "                        set.\n",
        "                        Default: None\n",
        "            fig_size (tuple, optional): Size of figure created.\n",
        "                        Default: (6,6)\n",
        "            use_pyplot (boolean, optional): If true, uses pyplot to create and show\n",
        "                        figure and displays the figure after creating. If False,\n",
        "                        uses Matplotlib object oriented API and simply returns a\n",
        "                        figure object without showing.\n",
        "                        Default: True.\n",
        "\n",
        "        Returns:\n",
        "            2-element tuple of **figure**, **axis**:\n",
        "            - **figure** (*matplotlib.pyplot.figure*):\n",
        "                        Figure object on which visualization\n",
        "                        is created. If plt_fig_axis argument is given, this is the\n",
        "                        same figure provided.\n",
        "            - **axis** (*matplotlib.pyplot.axis*):\n",
        "                        Axis object on which visualization\n",
        "                        is created. If plt_fig_axis argument is given, this is the\n",
        "                        same axis provided.\n",
        "\n",
        "        Examples::\n",
        "\n",
        "            >>> # ImageClassifier takes a single input tensor of images Nx3x32x32,\n",
        "            >>> # and returns an Nx10 tensor of class probabilities.\n",
        "            >>> net = ImageClassifier()\n",
        "            >>> ig = IntegratedGradients(net)\n",
        "            >>> # Computes integrated gradients for class 3 for a given image .\n",
        "            >>> attribution, delta = ig.attribute(orig_image, target=3)\n",
        "            >>> # Displays blended heat map visualization of computed attributions.\n",
        "            >>> _ = visualize_image_attr(attribution, orig_image, \"blended_heat_map\")\n",
        "    \"\"\"\n",
        "    # Create plot if figure, axis not provided\n",
        "    if plt_fig_axis is not None:\n",
        "        plt_fig, plt_axis = plt_fig_axis\n",
        "    else:\n",
        "        if use_pyplot:\n",
        "            plt_fig, plt_axis = plt.subplots(figsize=fig_size)\n",
        "        else:\n",
        "            plt_fig = Figure(figsize=fig_size)\n",
        "            plt_axis = plt_fig.subplots()\n",
        "\n",
        "    if original_image is not None:\n",
        "        if np.max(original_image) <= 1.0:\n",
        "            original_image = _prepare_image(original_image * 255)\n",
        "    else:\n",
        "        assert (\n",
        "            ImageVisualizationMethod[method] == ImageVisualizationMethod.heat_map\n",
        "        ), \"Original Image must be provided for any visualization other than heatmap.\"\n",
        "\n",
        "    # Remove ticks and tick labels from plot.\n",
        "    plt_axis.xaxis.set_ticks_position(\"none\")\n",
        "    plt_axis.yaxis.set_ticks_position(\"none\")\n",
        "    plt_axis.set_yticklabels([])\n",
        "    plt_axis.set_xticklabels([])\n",
        "\n",
        "    heat_map = None\n",
        "    # Show original image\n",
        "    if ImageVisualizationMethod[method] == ImageVisualizationMethod.original_image:\n",
        "        plt_axis.imshow(original_image)\n",
        "    else:\n",
        "        # Choose appropriate signed attributions and normalize.\n",
        "        norm_attr = _normalize_image_attr(attr, sign, outlier_perc)\n",
        "\n",
        "        # Set default colormap and bounds based on sign.\n",
        "        if VisualizeSign[sign] == VisualizeSign.all:\n",
        "            default_cmap = LinearSegmentedColormap.from_list(\n",
        "                \"RdWhGn\", [\"red\", \"white\", \"green\"]\n",
        "            )\n",
        "            vmin, vmax = -1, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.positive:\n",
        "            default_cmap = \"Greens\"\n",
        "            vmin, vmax = 0, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.negative:\n",
        "            default_cmap = \"Reds\"\n",
        "            vmin, vmax = 0, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.absolute_value:\n",
        "            default_cmap = \"Blues\"\n",
        "            vmin, vmax = 0, 1\n",
        "        else:\n",
        "            raise AssertionError(\"Visualize Sign type is not valid.\")\n",
        "        cmap = cmap if cmap is not None else default_cmap\n",
        "\n",
        "        # Show appropriate image visualization.\n",
        "        if ImageVisualizationMethod[method] == ImageVisualizationMethod.heat_map:\n",
        "            heat_map = plt_axis.imshow(norm_attr, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        elif (\n",
        "            ImageVisualizationMethod[method]\n",
        "            == ImageVisualizationMethod.blended_heat_map\n",
        "        ):\n",
        "            plt_axis.imshow(np.mean(original_image, axis=2), cmap=\"gray\")\n",
        "            heat_map = plt_axis.imshow(\n",
        "                norm_attr, cmap=cmap, vmin=vmin, vmax=vmax, alpha=alpha_overlay\n",
        "            )\n",
        "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.masked_image:\n",
        "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
        "                \"Cannot display masked image with both positive and negative \"\n",
        "                \"attributions, choose a different sign option.\"\n",
        "            )\n",
        "            plt_axis.imshow(\n",
        "                _prepare_image(original_image * np.expand_dims(norm_attr, 2))\n",
        "            )\n",
        "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.alpha_scaling:\n",
        "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
        "                \"Cannot display alpha scaling with both positive and negative \"\n",
        "                \"attributions, choose a different sign option.\"\n",
        "            )\n",
        "            plt_axis.imshow(\n",
        "                np.concatenate(\n",
        "                    [\n",
        "                        original_image,\n",
        "                        _prepare_image(np.expand_dims(norm_attr, 2) * 255),\n",
        "                    ],\n",
        "                    axis=2,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            raise AssertionError(\"Visualize Method type is not valid.\")\n",
        "\n",
        "    # Add colorbar. If given method is not a heatmap and no colormap is relevant,\n",
        "    # then a colormap axis is created and hidden. This is necessary for appropriate\n",
        "    # alignment when visualizing multiple plots, some with heatmaps and some\n",
        "    # without.\n",
        "    if show_colorbar:\n",
        "        axis_separator = make_axes_locatable(plt_axis)\n",
        "        colorbar_axis = axis_separator.append_axes(\"bottom\", size=\"5%\", pad=0.1)\n",
        "        if heat_map:\n",
        "            plt_fig.colorbar(heat_map, orientation=\"horizontal\", cax=colorbar_axis)\n",
        "        else:\n",
        "            colorbar_axis.axis(\"off\")\n",
        "    if title:\n",
        "        plt_axis.set_title(title)\n",
        "\n",
        "    if use_pyplot:\n",
        "        plt.show()\n",
        "\n",
        "    return plt_fig, plt_axis\n",
        "\n",
        "\n",
        "def visualize_image_attr_multiple(\n",
        "    attr: ndarray,\n",
        "    original_image: Union[None, ndarray],\n",
        "    methods: List[str],\n",
        "    signs: List[str],\n",
        "    titles: Union[None, List[str]] = None,\n",
        "    fig_size: Tuple[int, int] = (8, 6),\n",
        "    use_pyplot: bool = True,\n",
        "    **kwargs: Any\n",
        "):\n",
        "    r\"\"\"\n",
        "        Visualizes attribution using multiple visualization methods displayed\n",
        "        in a 1 x k grid, where k is the number of desired visualizations.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            attr (numpy.array): Numpy array corresponding to attributions to be\n",
        "                        visualized. Shape must be in the form (H, W, C), with\n",
        "                        channels as last dimension. Shape must also match that of\n",
        "                        the original image if provided.\n",
        "            original_image (numpy.array, optional):  Numpy array corresponding to\n",
        "                        original image. Shape must be in the form (H, W, C), with\n",
        "                        channels as the last dimension. Image can be provided either\n",
        "                        with values in range 0-1 or 0-255. This is a necessary\n",
        "                        argument for any visualization method which utilizes\n",
        "                        the original image.\n",
        "            methods (list of strings): List of strings of length k, defining method\n",
        "                            for each visualization. Each method must be a valid\n",
        "                            string argument for method to visualize_image_attr.\n",
        "            signs (list of strings): List of strings of length k, defining signs for\n",
        "                            each visualization. Each sign must be a valid\n",
        "                            string argument for sign to visualize_image_attr.\n",
        "            titles (list of strings, optional):  List of strings of length k, providing\n",
        "                        a title string for each plot. If None is provided, no titles\n",
        "                        are added to subplots.\n",
        "                        Default: None\n",
        "            fig_size (tuple, optional): Size of figure created.\n",
        "                        Default: (8, 6)\n",
        "            use_pyplot (boolean, optional): If true, uses pyplot to create and show\n",
        "                        figure and displays the figure after creating. If False,\n",
        "                        uses Matplotlib object oriented API and simply returns a\n",
        "                        figure object without showing.\n",
        "                        Default: True.\n",
        "            **kwargs (Any, optional): Any additional arguments which will be passed\n",
        "                        to every individual visualization. Such arguments include\n",
        "                        `show_colorbar`, `alpha_overlay`, `cmap`, etc.\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            2-element tuple of **figure**, **axis**:\n",
        "            - **figure** (*matplotlib.pyplot.figure*):\n",
        "                        Figure object on which visualization\n",
        "                        is created. If plt_fig_axis argument is given, this is the\n",
        "                        same figure provided.\n",
        "            - **axis** (*matplotlib.pyplot.axis*):\n",
        "                        Axis object on which visualization\n",
        "                        is created. If plt_fig_axis argument is given, this is the\n",
        "                        same axis provided.\n",
        "\n",
        "        Examples::\n",
        "\n",
        "            >>> # ImageClassifier takes a single input tensor of images Nx3x32x32,\n",
        "            >>> # and returns an Nx10 tensor of class probabilities.\n",
        "            >>> net = ImageClassifier()\n",
        "            >>> ig = IntegratedGradients(net)\n",
        "            >>> # Computes integrated gradients for class 3 for a given image .\n",
        "            >>> attribution, delta = ig.attribute(orig_image, target=3)\n",
        "            >>> # Displays original image and heat map visualization of\n",
        "            >>> # computed attributions side by side.\n",
        "            >>> _ = visualize_mutliple_image_attr([\"original_image\", \"heat_map\"],\n",
        "            >>>                     [\"all\", \"positive\"], attribution, orig_image)\n",
        "    \"\"\"\n",
        "    assert len(methods) == len(signs), \"Methods and signs array lengths must match.\"\n",
        "    if titles is not None:\n",
        "        assert len(methods) == len(titles), (\n",
        "            \"If titles list is given, length must \" \"match that of methods list.\"\n",
        "        )\n",
        "    if use_pyplot:\n",
        "        plt_fig = plt.figure(figsize=fig_size)\n",
        "    else:\n",
        "        plt_fig = Figure(figsize=fig_size)\n",
        "    plt_axis = plt_fig.subplots(1, len(methods))\n",
        "\n",
        "    # When visualizing one\n",
        "    if len(methods) == 1:\n",
        "        plt_axis = [plt_axis]\n",
        "\n",
        "    for i in range(len(methods)):\n",
        "        visualize_image_attr(\n",
        "            attr,\n",
        "            original_image=original_image,\n",
        "            method=methods[i],\n",
        "            sign=signs[i],\n",
        "            plt_fig_axis=(plt_fig, plt_axis[i]),\n",
        "            use_pyplot=False,\n",
        "            title=titles[i] if titles else None,\n",
        "            **kwargs\n",
        "        )\n",
        "    plt_fig.tight_layout()\n",
        "    if use_pyplot:\n",
        "        plt.show()\n",
        "    return plt_fig, plt_axis\n",
        "\n",
        "\n",
        "# These visualization methods are for text and are partially copied from\n",
        "# experiments conducted by Davide Testuggine at Facebook.\n",
        "\n",
        "\n",
        "class VisualizationDataRecord:\n",
        "    r\"\"\"\n",
        "        A data record for storing attribution relevant information\n",
        "    \"\"\"\n",
        "    __slots__ = [\n",
        "        \"word_attributions\",\n",
        "        \"pred_prob\",\n",
        "        \"pred_class\",\n",
        "        \"true_class\",\n",
        "        \"attr_class\",\n",
        "        \"attr_score\",\n",
        "        \"raw_input\",\n",
        "        \"convergence_score\",\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        word_attributions,\n",
        "        pred_prob,\n",
        "        pred_class,\n",
        "        true_class,\n",
        "        attr_class,\n",
        "        attr_score,\n",
        "        raw_input,\n",
        "        convergence_score,\n",
        "    ):\n",
        "        self.word_attributions = word_attributions\n",
        "        self.pred_prob = pred_prob\n",
        "        self.pred_class = pred_class\n",
        "        self.true_class = true_class\n",
        "        self.attr_class = attr_class\n",
        "        self.attr_score = attr_score\n",
        "        self.raw_input = raw_input\n",
        "        self.convergence_score = convergence_score\n",
        "\n",
        "\n",
        "# def _get_color(attr):\n",
        "#     # clip values to prevent CSS errors (Values should be from [-1,1])\n",
        "#     attr = max(-1, min(1, attr))\n",
        "#     if attr > 0:\n",
        "#         hue = 120\n",
        "#         sat = 75\n",
        "#         lig = 100 - int(90 * attr)\n",
        "#     else:\n",
        "#         hue = 0\n",
        "#         sat = 75\n",
        "#         lig = 100 - int(-80 * attr)\n",
        "#     return \"hsl({}, {}%, {}%)\".format(hue, sat, lig)\n",
        "\n",
        "\n",
        "def format_classname(classname):\n",
        "    return '<td><text style=\"padding-right:2em\"><b>{}</b></text></td>'.format(classname)\n",
        "\n",
        "\n",
        "def format_special_tokens(token):\n",
        "    if token.startswith(\"<\") and token.endswith(\">\"):\n",
        "        return \"#\" + token.strip(\"<>\")\n",
        "    return token\n",
        "\n",
        "\n",
        "def format_tooltip(item, text):\n",
        "    return '<div class=\"tooltip\">{item}\\\n",
        "        <span class=\"tooltiptext\">{text}</span>\\\n",
        "        </div>'.format(\n",
        "        item=item, text=text\n",
        "    )\n",
        "\n",
        "\n",
        "def format_word_importances(words, importances):\n",
        "    if importances is None or len(importances) == 0:\n",
        "        return \"<td></td>\"\n",
        "    assert len(words) <= len(importances)\n",
        "    tags = [\"<td>\"]\n",
        "    for word, importance in zip(words, importances[: len(words)]):\n",
        "        word = format_special_tokens(word)\n",
        "        color = _get_color(importance)\n",
        "        unwrapped_tag = '<mark style=\"background-color: {color}; opacity:1.0; \\\n",
        "                    line-height:1.75\"><font color=\"black\"> {word}\\\n",
        "                    </font></mark>'.format(\n",
        "            color=color, word=word\n",
        "        )\n",
        "        tags.append(unwrapped_tag)\n",
        "    tags.append(\"</td>\")\n",
        "    return \"\".join(tags)\n",
        "\n",
        "\n",
        "\n",
        "def visualize_text(datarecords: Iterable[VisualizationDataRecord]) -> None:\n",
        "    assert HAS_IPYTHON, (\n",
        "        \"IPython must be available to visualize text. \"\n",
        "        \"Please run 'pip install ipython'.\"\n",
        "    )\n",
        "    dom = [\"<table width: 65%>\"]\n",
        "    rows = [\n",
        "        \"<th>Predicted<br /> Label</th>\"\n",
        "        \"<th>Word Importance</th>\"\n",
        "    ]\n",
        "    for datarecord in datarecords:\n",
        "        rows.append(\n",
        "            \"\".join(\n",
        "                [\n",
        "                    \"<tr>\",\n",
        "                    format_classname(\n",
        "                        # \"{0} ({1:.2f})\".format(\n",
        "                            \"{0}\".format(\n",
        "                            label_dict[datarecord.pred_class.item()]\n",
        "                            # , 1-datarecord.pred_prob.item()\n",
        "                        )\n",
        "                    ),\n",
        "                    format_word_importances(\n",
        "                        datarecord.raw_input[1:-1], datarecord.word_attributions[1:-1]\n",
        "                    ),\n",
        "                    \"<tr>\",\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    dom.append(\"\".join(rows))\n",
        "    dom.append(\"</table>\")\n",
        "    display(HTML(\"\".join(dom)))\n",
        "\n",
        "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
        "\n",
        "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "    # construct input token ids\n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    # construct reference token ids \n",
        "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
        "\n",
        "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
        "\n",
        "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
        "    seq_len = input_ids.size(1)\n",
        "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
        "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
        "    return token_type_ids, ref_token_type_ids\n",
        "\n",
        "def construct_input_ref_pos_id_pair(input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
        "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
        "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
        "\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    return position_ids, ref_position_ids\n",
        "    \n",
        "def construct_attention_mask(input_ids):\n",
        "    return torch.ones_like(input_ids)\n",
        "\n",
        "\n",
        "def custom_forward(inputs):\n",
        "    preds = predict(inputs)\n",
        "    return torch.softmax(preds, dim = 1)[0][0].unsqueeze(-1)\n",
        "\n",
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    return attributions\n",
        "\n",
        "\n",
        "def fix_characters(text):\n",
        "    text = text.replace(\"‘\", \"'\")\n",
        "    text = text.replace(\"’\", \"'\")\n",
        "    text = text.replace(\"“\", \"\\\"\")\n",
        "    text = text.replace(\"”\", \"\\\"\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def predict(inputs):\n",
        "    return model(inputs)[0]\n",
        "\n",
        "\n",
        "def _get_color(attr):\n",
        "    # clip values to prevent CSS errors (Values should be from [-1,1])\n",
        "    attr = max(-1, min(1, attr))\n",
        "    if attr < 0:\n",
        "        hue = 360\n",
        "        sat = 1\n",
        "        lig = max([100 - int(-900 * attr), 50])\n",
        "    else:\n",
        "        hue = 200\n",
        "        sat = 100\n",
        "        lig = 100 #- int(90 * attr)\n",
        "\n",
        "    return \"hsl({}, {}%, {}%)\".format(hue, sat, lig)\n",
        "\n",
        "\n",
        "\n",
        "# lig = LayerIntegratedGradients(custom_forward, model.roberta.embeddings)\n",
        "lig = LayerIntegratedGradients(custom_forward, model.base_model.embeddings)\n",
        "# lig = LayerIntegratedGradients(custom_forward, model.embeddings)\n",
        "\n",
        "\n",
        "\n",
        "def robertainterp(text):\n",
        "\n",
        "    text = fix_characters(text)\n",
        "\n",
        "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "    # token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
        "    # position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "    # attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "    indices = input_ids[0].detach().tolist()\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
        "    all_tokens = [tok.replace('Ġ', '') for tok in all_tokens]\n",
        "\n",
        "    attributions, delta = lig.attribute(inputs=input_ids,\n",
        "                                        baselines=ref_input_ids,\n",
        "                                        return_convergence_delta=True)\n",
        "\n",
        "    score = predict(input_ids)\n",
        "\n",
        "    attributions_sum = summarize_attributions(attributions)\n",
        "\n",
        "    # if torch.argmax(torch.softmax(score, dim = 1)[0]).item() == 1:\n",
        "    #     attributions_sum = torch.mul(attributions_sum, -1)\n",
        "\n",
        "    score_vis = VisualizationDataRecord(\n",
        "                            attributions_sum,\n",
        "                            torch.softmax(score, dim = 1)[0][0],\n",
        "                            torch.argmax(torch.softmax(score, dim = 1)[0]),\n",
        "                            0,\n",
        "                            text,\n",
        "                            attributions_sum.sum(),       \n",
        "                            all_tokens,\n",
        "                            delta)\n",
        "\n",
        "    # print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
        "    visualize_text([score_vis])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVasUwBJpi7b"
      },
      "source": [
        "## Run it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPuuGuwV1AfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "37420c84459e426d9c9777389fa52f70",
            "6af640fbd5b34992a58d9b2f0c99df47",
            "8ee0b744719a4c1d9ff29dc6334c9f99"
          ]
        },
        "outputId": "9ff60aea-2dd1-4416-b211-0be2802568f7"
      },
      "source": [
        "text = widgets.Text(\n",
        "    value='You & your children won’t be SAFE in Biden’s America, and neither will anyone else!',\n",
        "    placeholder='Enter tweet to test here',\n",
        "    description='Tweet:',\n",
        "    disabled=False, \n",
        "    layout=Layout(width='75%', height='80px')\n",
        ")\n",
        "\n",
        "def callback(wdgt):\n",
        "    robertainterp(wdgt.value)\n",
        "\n",
        "display(text)\n",
        "callback(text)\n",
        "\n",
        "text.on_submit(callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37420c84459e426d9c9777389fa52f70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='You & your children won’t be SAFE in Biden’s America, and neither will anyone else!', description=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 65%><th>Predicted Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Not Polarizing</b></text></td><td><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> You                    </font></mark><mark style=\"background-color: hsl(360, 1%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> &                    </font></mark><mark style=\"background-color: hsl(360, 1%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> children                    </font></mark><mark style=\"background-color: hsl(360, 1%, 43%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> won                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 't                    </font></mark><mark style=\"background-color: hsl(360, 1%, 56%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(360, 1%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> SAF                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> E                    </font></mark><mark style=\"background-color: hsl(360, 1%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Biden                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 's                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> America                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> neither                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(360, 1%, 40%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> anyone                    </font></mark><mark style=\"background-color: hsl(360, 1%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> else                    </font></mark><mark style=\"background-color: hsl(360, 1%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "g2EwaUDPNi1K",
        "outputId": "da8e490a-4e00-402d-eb26-b382090f385e"
      },
      "source": [
        "robertainterp(\"The Trump Admin wants to create an unnecessary process that would hurt Minnesota home care workers, the majority of which are women, including many women of color. I'm standing up against this misguided attack with my fellow Minnesota colleagues.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 65%><th>Predicted Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Polarizing</b></text></td><td><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(360, 1%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Trump                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Admin                    </font></mark><mark style=\"background-color: hsl(360, 1%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wants                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(360, 1%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> create                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> an                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unnecessary                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> process                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(360, 1%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> would                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hurt                    </font></mark><mark style=\"background-color: hsl(360, 1%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Minnesota                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> home                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> workers                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(360, 1%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> majority                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(360, 1%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> which                    </font></mark><mark style=\"background-color: hsl(360, 1%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> women                    </font></mark><mark style=\"background-color: hsl(360, 1%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> including                    </font></mark><mark style=\"background-color: hsl(360, 1%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> many                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> women                    </font></mark><mark style=\"background-color: hsl(360, 1%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> color                    </font></mark><mark style=\"background-color: hsl(360, 1%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(360, 1%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 'm                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> standing                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> up                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> against                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(360, 1%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> misguided                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> attack                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(360, 1%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fellow                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Minnesota                    </font></mark><mark style=\"background-color: hsl(360, 1%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> colleagues                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "hiNLquFZOYg_",
        "outputId": "af4b2b38-85b5-4177-b830-64f389a2dd09"
      },
      "source": [
        "robertainterp(\"On this Memorial Day, join me in taking time to honor those who made the ultimate sacrifice & through that sacrifice blessed us with liberty\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 65%><th>Predicted<br /> Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>Not Polarizing</b></text></td><td><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> On                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Memorial                    </font></mark><mark style=\"background-color: hsl(360, 1%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Day                    </font></mark><mark style=\"background-color: hsl(360, 1%, 61%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(360, 1%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> join                    </font></mark><mark style=\"background-color: hsl(360, 1%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> me                    </font></mark><mark style=\"background-color: hsl(360, 1%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(360, 1%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> taking                    </font></mark><mark style=\"background-color: hsl(360, 1%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark><mark style=\"background-color: hsl(200, 100%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(360, 1%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> honor                    </font></mark><mark style=\"background-color: hsl(360, 1%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> those                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> who                    </font></mark><mark style=\"background-color: hsl(360, 1%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> made                    </font></mark><mark style=\"background-color: hsl(360, 1%, 52%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(360, 1%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ultimate                    </font></mark><mark style=\"background-color: hsl(360, 1%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sacrifice                    </font></mark><mark style=\"background-color: hsl(360, 1%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> &                    </font></mark><mark style=\"background-color: hsl(360, 1%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> through                    </font></mark><mark style=\"background-color: hsl(360, 1%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(360, 1%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sacrifice                    </font></mark><mark style=\"background-color: hsl(360, 1%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blessed                    </font></mark><mark style=\"background-color: hsl(360, 1%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(360, 1%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(360, 1%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> liberty                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzlINNhoM_lA"
      },
      "source": [
        "The Trump Admin wants to create an unnecessary process that would hurt Minnesota home care workers, the majority of which are women, including many women of color. I'm standing up against this misguided attack with my fellow minnesota colleagues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfVsbqMTNStL"
      },
      "source": [
        "On this Memorial Day, join me in taking time to honor those who made the ultimate sacrifice & through that sacrifice blessed us with liberty"
      ]
    }
  ]
}